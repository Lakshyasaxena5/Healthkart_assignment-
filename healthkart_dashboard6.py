import streamlit as st
import pandas as pd
import numpy as np
import random
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import matplotlib

matplotlib.rcParams['axes.facecolor'] = '#f0f2f6' # Match Streamlit theme

# PAGE CONFIGURATION
st.set_page_config(page_title="HealthKart Influencer Dashboard", layout="wide")

# SIMULATE DATA PARAMETERS
N_INFLUENCERS = 520
N_POSTS = 2600

platforms = ['Instagram', 'YouTube', 'Twitter', 'TikTok']
categories = ['Fitness', 'Nutrition', 'Lifestyle', 'Tech', 'Travel']
genders = ['Male', 'Female', 'Other']

brands = ['MuscleBlaze', 'HKVitals', 'Gritzo', 'TrueBasics', 'MBFoods', 'HealthViva']
products = ['Protein Powder', 'Vitamins', 'Shaker', 'Mass Gainer', 'Energy Bar']

np.random.seed(42)

# Function to simulate influencer data
def simulate_influencers(n):
    return pd.DataFrame({
        'influencer_id': ['INF' + str(i).zfill(4) for i in range(n)],
        'name': ['Influencer_' + str(i) for i in range(n)],
        'category': np.random.choice(categories, n),
        'gender': np.random.choice(genders, n),
        'follower_count': np.random.randint(10_000, 2_000_000, n),
        'platform': np.random.choice(platforms, n)
    })

# Function to simulate post data
def simulate_posts(influencers, n_posts):
    posts = []
    start_date = datetime(2023, 1, 1)
    end_date = datetime(2024, 1, 31)
    for _ in range(n_posts):
        infl = influencers.sample(1).iloc[0]
        # Ensure post date is within a reasonable range
        post_date = start_date + timedelta(days=np.random.randint(0, (end_date - start_date).days))
        posts.append({
            'influencer_id': infl['influencer_id'],
            'platform': infl['platform'],
            'date': post_date.strftime("%Y-%m-%d"),
            'url': f"https://post.com/{random.randint(10000,99999)}",
            'caption': f"Promo by {infl['name']}",
            'reach': np.random.randint(2000, max(2000, infl['follower_count'] // 2)),
            'likes': np.random.randint(100, 9000),
            'comments': np.random.randint(5, 900)
        })
    return pd.DataFrame(posts)

# Function to simulate tracking data (without baseline revenue for incremental ROAS)
def simulate_tracking_data(posts):
    tracking = []
    sample_size = min(len(posts), 2000) # Limit sample size to avoid excessive data
    for _, row in posts.sample(sample_size).iterrows():
        num_orders = np.random.randint(1, 4) # Number of orders generated by this post
        for _ in range(num_orders):
            revenue_generated = np.random.uniform(250.0, 3500.0)
            tracking.append({
                'source': np.random.choice(brands),
                'campaign': f"Spring_{np.random.randint(1,10)}",
                'influencer_id': row['influencer_id'],
                'user_id': 'U' + str(np.random.randint(1_000_000, 9_999_999)), # More distinct user IDs
                'product': np.random.choice(products),
                'date': row['date'],
                'orders': np.random.randint(1, 3), # Orders per user interaction
                'revenue': round(revenue_generated, 2)
            })
    return pd.DataFrame(tracking)

# Function to simulate payout data
def simulate_payouts(influencers):
    payouts = []
    for _, row in influencers.iterrows():
        basis = np.random.choice(['post', 'order'])
        rate = np.random.uniform(1000, 10000) if basis == 'post' else np.random.uniform(100, 500)
        n_orders = np.random.randint(10, 100) # Number of orders for 'order' basis payout
        total_payout = rate * (1 if basis == 'post' else n_orders)
        payouts.append({
            'influencer_id': row['influencer_id'],
            'basis': basis,
            'rate': round(rate, 2),
            'orders': n_orders if basis == 'order' else 0, # Only relevant for 'order' basis
            'total_payout': round(total_payout, 2)
        })
    return pd.DataFrame(payouts)

# Data Simulation
# Check if data is already in session state to avoid re-simulation on every rerun
if 'influencers_df' not in st.session_state:
    with st.spinner("Simulating data..."):
        st.session_state.influencers_df = simulate_influencers(N_INFLUENCERS)
        st.session_state.posts_df = simulate_posts(st.session_state.influencers_df, N_POSTS)
        st.session_state.tracking_df = simulate_tracking_data(st.session_state.posts_df)
        st.session_state.payouts_df = simulate_payouts(st.session_state.influencers_df)

influencers_df = st.session_state.influencers_df
posts_df = st.session_state.posts_df
tracking_df = st.session_state.tracking_df
payouts_df = st.session_state.payouts_df

# Convert date columns to datetime objects for proper filtering
posts_df['date'] = pd.to_datetime(posts_df['date'])
tracking_df['date'] = pd.to_datetime(tracking_df['date'])

# --- Sidebar Filters ---
st.sidebar.header("🔍 Filter Data")

# Date Range Filter
min_date = tracking_df['date'].min().date() if not tracking_df.empty else datetime.now().date()
max_date = tracking_df['date'].max().date() if not tracking_df.empty else datetime.now().date()

date_range = st.sidebar.date_input(
    "Select Date Range",
    value=(min_date, max_date),
    min_value=min_date,
    max_value=max_date
)

# Ensure date_range has two dates before proceeding
if len(date_range) == 2:
    start_date_filter = datetime.combine(date_range[0], datetime.min.time())
    end_date_filter = datetime.combine(date_range[1], datetime.max.time())
else: # Default to full range if only one date is selected initially
    start_date_filter = datetime.combine(min_date, datetime.min.time())
    end_date_filter = datetime.combine(max_date, datetime.max.time())


platform_sel = st.sidebar.multiselect("Platform", platforms, platforms)
brand_sel = st.sidebar.multiselect("Brand", brands, brands)
category_sel = st.sidebar.multiselect("Category", categories, categories)
product_sel = st.sidebar.multiselect("Product", products, products)

# Apply filters
filtered_influencers = influencers_df[
    influencers_df['platform'].isin(platform_sel) &
    influencers_df['category'].isin(category_sel)
]

filtered_posts = posts_df[
    (posts_df['influencer_id'].isin(filtered_influencers['influencer_id'])) &
    (posts_df['date'] >= start_date_filter) &
    (posts_df['date'] <= end_date_filter)
]

filtered_tracking = tracking_df[
    (tracking_df['influencer_id'].isin(filtered_influencers['influencer_id'])) &
    (tracking_df['source'].isin(brand_sel)) &
    (tracking_df['product'].isin(product_sel)) &
    (tracking_df['date'] >= start_date_filter) &
    (tracking_df['date'] <= end_date_filter)
]

filtered_payouts = payouts_df[
    payouts_df['influencer_id'].isin(filtered_influencers['influencer_id'])
]

# --- Calculation Functions ---
def safe_div(a, b):
    return a / b if b > 0 else 0

# --- Key Performance Indicators (KPIs) ---
st.markdown("### 📊 Campaign Performance Metrics")

total_revenue = filtered_tracking['revenue'].sum()
total_payout = filtered_payouts['total_payout'].sum()

roas = safe_div(total_revenue, total_payout)

col1, col2, col3 = st.columns(3) # Changed to 3 columns as Incremental ROAS is removed
col1.metric(label="Total Revenue", value=f"₹{total_revenue:,.0f}")
col2.metric(label="Total Payout", value=f"₹{total_payout:,.0f}")
col3.metric(label="ROAS (x)", value=f"{roas:.2f}", delta="Good" if roas >= 2.5 else "Fair" if roas >= 1 else "Poor") # Adjusted delta logic


# --- Top Influencers by Revenue ---
st.markdown("### 🏆 Top Influencers by Revenue")
if not filtered_tracking.empty:
    top_inf = (filtered_tracking.groupby('influencer_id')['revenue'].sum()
               .reset_index()
               .merge(filtered_influencers, on='influencer_id')
               .sort_values('revenue', ascending=False)
               .head(10))
    st.dataframe(top_inf[['name', 'platform', 'category', 'follower_count', 'revenue']],
                 use_container_width=True)
else:
    st.info("No data available for selected filters to show top influencers by revenue.")


# --- Revenue by Brand ---
st.markdown("### 📈 Revenue by Brand")
if not filtered_tracking.empty:
    brand_rev = filtered_tracking.groupby('source')['revenue'].sum().sort_values(ascending=False)
    st.bar_chart(brand_rev, use_container_width=True)
else:
    st.info("No data available for selected brand filters.")

# --- Distribution of Influencers by Category ---
st.markdown("### 🏷️ Distribution of Influencers by Category")
if not filtered_influencers.empty:
    category_counts = filtered_influencers['category'].value_counts()
    st.bar_chart(category_counts, use_container_width=True)
else:
    st.info("No influencer data available for selected category filters.")

# --- Revenue Share by Product (Pie Chart) ---
st.markdown("### 🥇 Revenue Share by Product")
product_rev = filtered_tracking.groupby('product')['revenue'].sum()
if not product_rev.empty:
    fig, ax = plt.subplots(facecolor='#f0f2f6')
    ax.set_facecolor('#f0f2f6')
    # Ensure colors are sufficient for all slices
    colors = plt.cm.Paired.colors + plt.cm.Set3.colors # Combine colormaps for more distinct colors
    product_rev.plot.pie(ax=ax, autopct='%1.1f%%', ylabel='', legend=False, colors=colors[:len(product_rev)])
    st.pyplot(fig)
else:
    st.info("No product revenue data available.")

# --- Revenue Over Time ---
st.markdown("### 📊 Revenue Trend Over Time")
if not filtered_tracking.empty:
    # Group by date and sum revenue, then sort by date
    revenue_over_time = filtered_tracking.groupby(filtered_tracking['date'].dt.date)['revenue'].sum().reset_index()
    revenue_over_time.columns = ['Date', 'Revenue']
    st.line_chart(revenue_over_time.set_index('Date'), use_container_width=True)
else:
    st.info("No tracking data available to show revenue trends.")

# --- Detailed Influencer Campaign Table ---
st.markdown("### 📋 Detailed Influencer Campaign Table")
# Merge relevant dataframes for a comprehensive view
if not filtered_influencers.empty:
    merged_df = filtered_influencers.merge(filtered_payouts, on='influencer_id', how='left')
    # Add revenue and ROAS to the detailed table
    influencer_perf_summary = (filtered_tracking.groupby('influencer_id')
                               .agg(total_revenue=('revenue', 'sum'))
                               .reset_index())
    merged_df = merged_df.merge(influencer_perf_summary, on='influencer_id', how='left')
    merged_df['total_revenue'] = merged_df['total_revenue'].fillna(0)
    merged_df['roas'] = merged_df.apply(lambda row: safe_div(row['total_revenue'], row['total_payout']), axis=1)

    st.dataframe(merged_df[['name', 'platform', 'category', 'follower_count', 'basis', 'rate', 'total_payout', 'total_revenue', 'roas']],
                 use_container_width=True)
else:
    st.info("No influencer data available for the detailed campaign table.")


# --- Export Filtered Data ---
st.markdown("### ⬇️ Export Filtered Data")
for name, df in {
    'Influencers': filtered_influencers,
    'Posts': filtered_posts,
    'Tracking': filtered_tracking,
    'Payouts': filtered_payouts
}.items():
    st.download_button(
        label=f"Download {name} as CSV",
        data=df.to_csv(index=False).encode('utf-8'), # Encode for proper download
        file_name=f"{name.lower()}_filtered.csv",
        mime="text/csv", # Specify mime type
        disabled=df.empty
    )

# --- Upload New Data (Placeholder for more robust ingestion) ---
uploaded_file = st.file_uploader("Or Upload New Influencer Data (CSV)", type=["csv"])
if uploaded_file:
    try:
        uploaded_df = pd.read_csv(uploaded_file)
        st.write("Preview of uploaded data:")
        st.dataframe(uploaded_df.head(), use_container_width=True)
        st.success("File uploaded successfully! Note: This currently only previews data and does not merge with the simulated data.")
        # In a real app, you would merge this with your existing dataframes or process it
    except Exception as e:
        st.error(f"Error reading file: {e}. Please ensure it's a valid CSV.")


# --- Insights & Analytical Summary ---
st.markdown("### 🔎 Insights & Analytical Summary")

if filtered_tracking.empty or filtered_payouts.empty:
    st.info("No sufficient data to generate insights. Adjust your filters.")
else:
    # Calculate performance metrics for each influencer
    influencer_perf = (
        filtered_tracking.groupby('influencer_id')
        .agg(total_revenue=('revenue', 'sum'))
        .reset_index()
        .merge(filtered_payouts[['influencer_id', 'total_payout']], on='influencer_id', how='left')
    )
    influencer_perf['total_payout'] = influencer_perf['total_payout'].fillna(0) # Handle influencers with no payout data
    influencer_perf['roas'] = influencer_perf.apply(
        lambda row: safe_div(row['total_revenue'], row['total_payout']),
        axis=1
    )
    full_perf = influencer_perf.merge(filtered_influencers, on='influencer_id')

    # Top Influencers by ROAS
    top_by_roas = full_perf.sort_values(by='roas', ascending=False).head(10)
    st.markdown("**Top Influencers by ROAS**")
    st.dataframe(
        top_by_roas[['name', 'platform', 'category', 'gender', 'follower_count', 'total_revenue', 'total_payout', 'roas']],
        use_container_width=True)

    # Best Performing Influencer Personas by ROAS
    persona_roas = (
        full_perf.groupby(['category', 'platform', 'gender'])['roas']
        .mean()
        .reset_index()
        .sort_values(by='roas', ascending=False)
    )
    st.markdown("**Best Performing Influencer Personas (Category + Platform + Gender Average ROAS)**")
    st.dataframe(persona_roas, use_container_width=True)

    # ROAS by Brand
    brand_roas = {}
    for brand in filtered_tracking['source'].unique():
        brand_rev = filtered_tracking.loc[filtered_tracking['source'] == brand, 'revenue'].sum()

        # Get influencers associated with this brand's tracking data
        brand_infl_ids = filtered_tracking.loc[filtered_tracking['source'] == brand, 'influencer_id'].unique()
        # Sum payouts for these specific influencers
        payout_sum = filtered_payouts.loc[filtered_payouts['influencer_id'].isin(brand_infl_ids), 'total_payout'].sum()

        brand_roas[brand] = safe_div(brand_rev, payout_sum)

    st.markdown("**ROAS by Brand**")
    st.dataframe(
        pd.DataFrame(brand_roas.items(), columns=['Brand', 'ROAS']).sort_values(by='ROAS', ascending=False),
        use_container_width=True)

    # Influencers with Poor ROAS (Below a threshold, e.g., 1)
    poor_roas_influencers = full_perf[full_perf['roas'] < 1].sort_values('roas').head(10)
    st.markdown("**Influencers with Poor ROAS (Below 1)**")
    st.dataframe(
        poor_roas_influencers[['name', 'platform', 'category', 'gender', 'total_revenue', 'total_payout', 'roas']],
        use_container_width=True)

    # Consolidated Insights Summary
    best_persona = persona_roas.iloc[0] if not persona_roas.empty else None
    top_brands_list = sorted(brand_roas.items(), key=lambda x: x[1], reverse=True)[:3]
    top_brands_names = ', '.join([b for b, r in top_brands_list if r > 0]) or "No brands with positive ROAS"

    if best_persona is not None:
        insights_text = f"""
- The best performing influencer persona by **ROAS** is **{best_persona['category']}** category on **{best_persona['platform']}** platform,
  with **{best_persona['gender']}** influencers generating an average ROAS of **{best_persona['roas']:.2f}x**.
- Top brands by ROAS are: {top_brands_names}.
- Consider reviewing influencers with ROAS below 1 to optimize future campaigns and re-evaluate their effectiveness.
"""
    else:
        insights_text = "No sufficient data to generate detailed insights. Please adjust your filters."
    st.markdown(insights_text)
